---
title: "evils: Evaluate Extreme Value Likelihoods Safely"
author: "Paul Northrop"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{evils: Evaluate Extreme Value Likelihoods Safely}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: evils.bib
csl: taylor-and-francis-chicago-author-date.csl
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

We make use of the Maclaurin series expansion for $\log(1+x)$, where $\log$ is the natural logarithm

$$
\log(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots = \sum_{i=1}^\infty (-1)^{i-1} \frac{x ^ i}{i},
$$
which converges for $-1 < x \leq 1$.  We also use the binomial series

$$
(1+x)^{-1} = 1 - x + x^2 - x^3 + \cdots = \sum_{i=0}^\infty (-1)^i x^i,
$$
which converges for $|x| < 1$.
In cases where the extreme value shape parameter $\xi$ is very close to zero we truncate an infinite series expansion $\sum_{n=0}^\infty a_n$ to approximate parts of the quantities of interest for which direct evaluation is unreliable.  This is performed using the `infiniteSum()` function in the **sumR** package [@sumR], which adds terms to the expansion until a desired accuracy has been achieved.  The algorithm that `infiniteSum()` uses depends on whether the series is alternating and, if it is alternating, the sign of the first term.  If the series is not alternating then the speed of convergence can be improved by providing the value of $\lim_{n \rightarrow \infty}\log(a_{n+1}/a_n)$ via the argument `logL` to `infiniteSum()`.  The main argument to `infiniteSum()` is `logFunction`, which is a function that returns $\log|a_n|$.

I the following we first consider the contribution from a single observations $y$ and then modify expressions to deal with a random sample of observations $y_1, ..., y_m$.

## Generalised Pareto (GP) distribution

The density function of a GP distribution with scale parameter $\sigma_u$ and shape parameter $\xi$ is given by 

$$
f_Y(y) = \sigma_u^{-1} \left(1 + \frac{\xi y}{\sigma_u}\right)_+ ^ {-(1 + 1/\xi)},
$$
where $\sigma_u>0$ and $y > 0$ when $\xi \geq 0$ and $0 < y < - \sigma_u/\xi$ when $\xi < 0$.
We let $z = \xi / \sigma_u$, which has the same sign as $\xi$.

### GP log-likelihood

The contribution of $y$ to the log-likelihood is given by
\begin{align*}
\ell(\sigma_u, \xi; y) &= -\log \sigma_u -(1 + 1/\xi) \log \left(1 + zy\right) \\
&= -\log \sigma_u -\frac{\xi + 1}{\xi} \sum_{i=1}^\infty (-1)^{i-1} \frac{z^i y^i}{i} \\
&= -\log \sigma_u - \frac{\xi+1}{\sigma_u}\sum_{n=0}^\infty \frac{(-1)^n}{n+1} z^n y^{n+1}, \\
\end{align*}
where $n = i-1$.  If $\xi$ is very close to zero then direct evaluation of the second term using the first line above can be unreliable.  If the `log1p()` is used then $\xi$ would need to be extremely close to zero for there to be a problem.  We illustrate this using simulated data.

```{r}
library(evils)
set.seed(15042022)
y <- rGenPareto(100, 0, 1, 0)
# Log-likelihood value for xi = 0
gpLogLikelihood(pars = c(1, 0), excesses = y)
# Direct calculation, involving (1 + 1 / xi) * log1p(xi * y / sigmau)
# Mostly fine, but breaks down eventually
gpLogLikDirect(pars = c(1, 1e-300), excesses = y)
gpLogLikDirect(pars = c(1, 1e-309), excesses = y)
```

However, it is worth considering the use of the series expansion. In practice only a small number of terms are needed to achieve a good approximation.

Therefore, 
$$
\log |a_n| = \log(\xi+1) - \log \sigma_u - \log(n+1) + n \log |z| + (n + 1) \log y.
$$
Provided that $\xi > 1$ the first term of this sum is positive.  If $\xi > 0$ then the series is alternating.  If $\xi < 0$ the series is not alternating and $\lim_{n \rightarrow \infty}\log(a_{n+1}/a_n) = \log |z| + \log y$.

If we have a sample $y_1, \ldots, y_m$ then the log-likelihood is given by
\begin{align*}
\ell(\sigma_u, \xi; y_1, \ldots, y_m) &= -m\log \sigma_u -(1 + 1/\xi) \sum_{j=1}^m \log \left(1 + zy_j\right) \\
&= -m\log \sigma_u - \frac{\xi+1}{\sigma_u}\sum_{n=0}^\infty \frac{(-1)^n}{n+1} z^n \sum_{j=1}^m y_j^{n+1}. \\
\end{align*}

This series has the same general properties as the previous one but now 
$$
\log |a_n| = \log(\xi+1) - \log \sigma_u - \log(n+1) + n \log |z| + (n + 1) \log \left(\sum_{j=1}^m y_j^{n+1}\right) .
$$
and $\lim_{n \rightarrow \infty}\log(a_{n+1}/a_n) = m\log |z| + \sum_{j=1}^m \log y_j$.

```{r}
# Approximation using sumR::infinitesum()
gpLogLikelihood(pars = c(1, 1e-8), excesses = y)
gpLogLikelihood(pars = c(1, -1e-8), excesses = y)
gpLogLikelihood(pars = c(1, 0), excesses = y)
```

### GP score

The score is the vector of partial derivatives of the log-likelihood with with respect to the parameter vector.  The derivative with respect to $\sigma_u$, that is,
$$
\frac{\partial \ell(\sigma_u, \xi; y)}{\partial \sigma_u} = -\sigma_u^{-1} + \sigma_u^{-2} (\xi+1) y(1+zy)^{-1}.
$$

can be evaluated directly for all values of $\xi$.  However, direct evaluation of

$$
\frac{\partial \ell(\sigma_u, \xi; y)}{\partial \xi} = \sigma_u^{-2}z^{-2} \log(1+zy) - \sigma_u^{-2}z^{-1} y (1+zy)^{-1} - \sigma_u^{-1} y (1+zy)^{-1}.
$$

will be unreliable when $\xi$ is very close to zero.

### GP observed information

$$i_{22} = \frac{2}{\xi^3} \log(1 + \xi y / \sigma) - 
\frac{2y}{\sigma \xi^2 (1 + \xi y / \sigma)} - \frac{y^2}{\sigma^2 \xi (1 + \xi y / \sigma) ^ 2} - \frac{y^2}{\sigma^2(1 + \xi y / \sigma)^2}.$$

```{r setup}
library(evils)
```

```{r data}
y <- rGenPareto(100, 0, 1, 0)
```

```{r calculations}
p <- -(4:10)
xi <- c(-10 ^ p, 0, 10 ^ rev(p))
infoFn <- function(xi, direct = FALSE) {
  if (direct) {
    i22 <- gpInfoDirect(pars = c(1, xi), excesses = y)[2, 2]
  } else {
    i22 <- gpInfo(pars = c(1, xi), excesses = y)[2, 2]
  }
  return(i22)
}
i1 <- sapply(xi, FUN = infoFn, direct = FALSE)
i2 <- sapply(xi, FUN = infoFn, direct = TRUE)
```

```{r table, echo = FALSE} 
cbind(xi, gpInfo = i1, gpInfoDirect = i2)
```

```{r plot, fig.width = 7, fig.height = 5, echo = FALSE}
matplot(1:length(xi), cbind(i1, i2), type = "l", axes = FALSE, xlab = "xi",
        ylab = "I(2,2)")
xlabels <- expression(-10^{-2})
xlabels <- c(
  expression(-10^{-4}), expression(-10^{-5}), expression(-10^{-6}),
  expression(-10^{-7}), expression(-10^{-8}), expression(-10^{-9}),
  expression(-10^{-10}), 0, expression(10^{-10}),
  expression(10^{-9}), expression(10^{-8}), expression(10^{-7}),
  expression(10^{-6}), expression(10^{-5}), expression(10^{-4})
  )
axis(1, at = 1:length(xi), labels = xlabels) 
axis(2)
```

## Observed information matrix

Let $x = \xi / \sigma$.

\begin{align*}
i_{22}
&= \frac{2}{\sigma ^ 3} \log(1 + \frac{})
mx + c \\
&= x \\
&= x_2.
\end{align*}

## References

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({  "HTML-CSS": { minScaleAdjust: 125, availableFonts: [] }  });
</script>
